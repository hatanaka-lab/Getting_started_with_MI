{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFd3Vca851px"
      },
      "source": [
        "# **ボストン住宅価格のデータから、価格を予測する機械学習モデルを作る**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyExQ5-r6vJB"
      },
      "source": [
        "データ解析練習用データセットの定番「ボストン住宅価格データ」をExcelにまとめました。\n",
        "\n",
        "ボストン市内の490件の住宅に対し、\n",
        "町ごとの犯罪率(CRIM)、雇用センターまでのの距離(DIS)、生徒教師比率(PTRATIO)・・・などなど、\n",
        "\n",
        "住宅価格に影響しそうな条件と、実際の価格(Price)がまとめられています。\n",
        "\n",
        "Excelファイルには、シートが２枚あり、\n",
        "\n",
        "「For ML」シートには、490件の住宅の条件と価格\n",
        "\n",
        "「For Prediction」シートには、予測したい住宅の条件（価格は未知）\n",
        "が記載されています。\n",
        "\n",
        "\n",
        "For MLのデータを元に、住宅価格を予測する機械学習モデルを作り、\n",
        "For Predictionの条件に対する価格を予測しましょう。\n",
        "\n",
        "\n",
        "Excelファイルはこちらから取得できます。\n",
        "https://github.com/hatanaka-lab/Getting_started_with_MI/tree/main/data/Boston.xlsx\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxOAf-YDPjgZ"
      },
      "source": [
        "#必要そうなライブラリたちをインポート\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#matplotlibで作成する図の中に日本語のフォントを利用する場合はこちらもインポート\n",
        "!pip install japanize-matplotlib\n",
        "import japanize_matplotlib"
      ],
      "metadata": {
        "id": "a4aiBx5utWre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNFYDrLs-0o9"
      },
      "source": [
        "# **STEP1：データの読み込み**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcejiEeQPGwZ"
      },
      "source": [
        "# Excelファイルの「For ML」Sheetからﾃﾞｰﾀを読み込んで、dfに代入\n",
        "# dfは\"data frame\"の略。\n",
        "# Pythonでは、\"pandas\"のdata frameと\"numpy\"のarrayの2種類をよく使うので、どちらか混乱しないように、data frameにはdfと名前を付ける癖をつけるとよい\n",
        "df = pd.read_excel(\"Boston.xlsx\", sheet_name='For ML')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfvybSPmPcew"
      },
      "source": [
        "# dfの中身を確認①\n",
        "# 各列の名前やﾃﾞｰﾀの個数（ぬけがないか等々）をcheck\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTIUpYe2PyDJ"
      },
      "source": [
        "# df の中身を確認②\n",
        "# ﾃﾞｰﾀを上から３行だけ見てみる head(#) の#の数で表示する行数を指定\n",
        "df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STEP2：データを観察**"
      ],
      "metadata": {
        "id": "wEAASWggfPaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データの分布を観察する：その1\n",
        "df_Target=df.drop(columns=['No'])\n",
        "pd.plotting.scatter_matrix(df_Target, figsize=(12, 12), hist_kwds={'bins':10},\n",
        "                           marker=('o'), s=8, alpha=.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QKDMBokWfULe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# データの分布を観察する：その2（相関行列）\n",
        "correlation_coefficients = df_Target.corr()  # 相関行列の計算\n",
        "# 相関行列のヒートマップ (相関係数の値あり)\n",
        "plt.rcParams['font.size'] = 9\n",
        "plt.figure(figsize=(12, 10))  # この段階で画像のサイズを指定する\n",
        "sns.heatmap(correlation_coefficients, vmax=1, vmin=-1, cmap='seismic', square=True, annot=True, xticklabels=1, yticklabels=1)\n",
        "plt.xlim([0, correlation_coefficients.shape[0]])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j0U56Gm1gTVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zolWgS_o5hSF"
      },
      "source": [
        "# **STEP3：データを切り分け**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8B1Y_mEQGa5"
      },
      "source": [
        "# dfの1～14列の手前までをXに代入（説明変数に利用）\n",
        "# 列数は、0からカウント。だから、Noが0列目、CRIMが1列目、LSTATが13行目\n",
        "X = np.array(df.iloc[:,1:14])\n",
        "df.iloc[:,1:14].head(2)  #中身の確認用"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FXL6dKLQUlq"
      },
      "source": [
        "# Priceとラベル付けされた列をYに代入（目的変数に利用）\n",
        "Y = np.array(df[\"Price\"])\n",
        "df[\"Price\"].head(2)  #中身の確認用"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-BoLkHRQ85Z"
      },
      "source": [
        "#　説明変数を標準化する\n",
        "#　標準化された値 = (元の値－平均値)/標準偏差\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "X_scaled = scaler.transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eTvS1WnRVL5"
      },
      "source": [
        "# ホールドアウト検証用にﾃﾞｰﾀを　訓練ﾃﾞｰﾀ（train)と検証用ﾃﾞｰﾀ（test）に分ける。\n",
        "# 分け方はランダム（今回は、train : test = 80% : 20%に分ける）\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, Y, test_size=0.2,random_state=999)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STEP4：ハイパーパラメタの決定**"
      ],
      "metadata": {
        "id": "GnvTjkWJK-zT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomForest用にハイパーパラメタを決める\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "list_param = []\n",
        "list_score = []\n",
        "for ne in range(5,250,50):\n",
        "  for nd in range(5,41,5):\n",
        "    model = RandomForestRegressor(n_estimators=ne, max_depth=nd, random_state=555)\n",
        "    cv5_score = cross_val_score(model, X_train, y_train, cv=5).mean()  #訓練用データ(train)を用いて5-fold CV\n",
        "    print(\"num_trees=\",ne,\"max_depth=\",nd,\"R2_score=\",cv5_score)\n",
        "    list_param.append([ne,nd])\n",
        "    list_score.append(cv5_score)\n",
        "max_index = np.argmax(list_score)\n",
        "print(\"\")\n",
        "print(\"-----Best parameters-----\")\n",
        "print(\"num_trees=\",list_param[max_index][0], \"max_depth=\",list_param[max_index][1],\"R2_score=\",list_score[max_index])"
      ],
      "metadata": {
        "id": "SUr2VBAKLGQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXytC6Ct_iI1"
      },
      "source": [
        "# **STEP5：機械学習実行**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06dYqydD_4lB"
      },
      "source": [
        "この直後に出てくる、RandomForestRegressorの部分を他の機械学習の方法名に置き換えると、色々な方法を試すことができる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRTYjwklSwP_"
      },
      "source": [
        "#　機械学習実行\n",
        "#  Random Forest回帰を採用\n",
        "#  これを実行すると、「model」の中身が 訓練ﾃﾞｰﾀから作られた機械学習モデルになる\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model = RandomForestRegressor(n_estimators=155,max_depth=25,random_state=1)\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxP2YpzeS-hR"
      },
      "source": [
        "# 機械学習モデルの妥当性を検証\n",
        "# 訓練ﾃﾞｰﾀとテストデータのスコアを見る　（scoreが1に近い程良いモデル）\n",
        "print(\"Score for Training Data:\", model.score(X_train,y_train))\n",
        "print(\"Score for Test Data    :\", model.score(X_test ,y_test ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v48tu3ckTOuB"
      },
      "source": [
        "# 散布図を描く\n",
        "# 横軸が実際の値(y)：縦軸が機械学習モデルから予測した値\n",
        "# データが対角線上にある程、予測精度が高いことを意味する\n",
        "plt.figure(figsize=(4,4))\n",
        "plt.scatter(y_train,model.predict(X_train),c='b',marker='o',alpha=0.7,label='Train')\n",
        "plt.scatter(y_test, model.predict(X_test ),c='r',marker='^',alpha=0.7,label='Test')\n",
        "# 対角線をひく\n",
        "x1 = np.linspace(-1, 50, 100)\n",
        "plt.plot(x1, x1, linestyle='-',c=\"silver\")\n",
        "#\n",
        "plt.title(\"Random Forest 回帰\", fontsize=14)\n",
        "plt.ylabel(\"予測値\", fontsize=12)\n",
        "plt.xlabel(\"実際の値\", fontsize=12)\n",
        "plt.legend(fontsize=12)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmyGsOJPDFfL"
      },
      "source": [
        "横軸：実際の値、縦軸：機械学習による予測値。データが対角線上にあるほど、予測精度が良いことを示す。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56l2h3JI_pgO"
      },
      "source": [
        "# **STEP6：住宅価格が未知のデータに対する予測**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siOTxx5HTYpL"
      },
      "source": [
        "# ここで、Priceの分からない未知のデータの説明変数（X)を読み込む\n",
        "df_Pred = pd.read_excel(\"Boston.xlsx\", sheet_name='For Prediction')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW8VW_Fs2gLX"
      },
      "source": [
        "# ﾃﾞｰﾀはX_Predに代入\n",
        "X_Pred = np.array(df_Pred.iloc[:,1:14])\n",
        "df_Pred.iloc[:,1:14].head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqrQHEzN2vYa"
      },
      "source": [
        "#　説明変数を標準化する\n",
        "#  機械学習モデルを作った時に定義したscalerをそのまま適用\n",
        "X_Pred_scaled = scaler.transform(X_Pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhjqA_Rm3Ifs"
      },
      "source": [
        "#　機械学習モデルに入力して、Priceの値を算出\n",
        "model.predict(X_Pred_scaled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et18uL6U3Yoj"
      },
      "source": [
        "# 上の表記だと、予測したいサンプルが多数ある場合に見にくいので、Excelに書き出す\n",
        "df_result = pd.DataFrame(model.predict(X_Pred_scaled))\n",
        "df_summary = pd.concat([df_Pred, df_result], axis=1)\n",
        "df_summary.to_excel(\"Boston_result.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI_A7m0P4Hs1"
      },
      "source": [
        "# ファイルダウンロード方法①\n",
        "# Google Colab画面の左側の「ファイル」ボタンをクリック\n",
        "# Boston_results.xlsxにカーソルを合わせ、右側の「縦に・が3つ並んだマーク」をクリック→ダウンロードをクリック\n",
        "\n",
        "# ファイルダウンロード方法②\n",
        "# 下記コードでもダウンロード可能\n",
        "#from google.colab import files\n",
        "#downloaded = files.download(\"Boston_result.xlsx\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rbnq-jMzDg6a"
      },
      "source": [
        "ダウンロードファイルの一番右側の列に、予測価格が書き込まれています。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQfVmdIaAxro"
      },
      "source": [
        "# **おまけ：他の機械学習モデルも色々検討**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "例１：PLS回帰"
      ],
      "metadata": {
        "id": "YiB-U8XupQlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomForest用にハイパーパラメタを決める\n",
        "from sklearn.cross_decomposition import PLSRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "list_param = []\n",
        "list_score = []\n",
        "for k in range(2,13,1):\n",
        "  model = PLSRegression(n_components=k)\n",
        "  cv5_score = cross_val_score(model, X_train, y_train, cv=5).mean()  #訓練用データ(train)を用いて5-fold CV\n",
        "  print(\"n_components=\", k, \"R2_score=\", cv5_score)\n",
        "  list_param.append(k)\n",
        "  list_score.append(cv5_score)\n",
        "max_index = np.argmax(list_score)\n",
        "print(\"\")\n",
        "print(\"-----Best parameters-----\")\n",
        "print(\"n_components=\",list_param[max_index],\"R2_score=\",list_score[max_index])"
      ],
      "metadata": {
        "id": "rWObqDTznivg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXT7Dcbh4Xn6"
      },
      "source": [
        "# 機械学習の方法を選択\n",
        "# 今回はPLS回帰（個人的にはお気に入り）\n",
        "from sklearn.cross_decomposition import PLSRegression\n",
        "model = PLSRegression(n_components=8)\n",
        "\n",
        "# 機械学習実行：ここから後ろは、RandomForestの時と変更なし\n",
        "model.fit(X_train, y_train)\n",
        "# 検証\n",
        "print(\"Score for Training Data:\", model.score(X_train,y_train))\n",
        "print(\"Score for Test Data    :\", model.score(X_test ,y_test ))\n",
        "# 散布図描画\n",
        "plt.figure(figsize=(4,4))\n",
        "plt.scatter(y_train,model.predict(X_train),c='b',marker='o',alpha=0.7,label='Train')\n",
        "plt.scatter(y_test, model.predict(X_test ),c='r',marker='^',alpha=0.7,label='Test')\n",
        "x1 = np.linspace(-1, 50, 100)\n",
        "plt.plot(x1, x1, linestyle='-',c=\"silver\")\n",
        "plt.title(\"PLS回帰\", fontsize=14)\n",
        "plt.ylabel(\"予測値\", fontsize=12)\n",
        "plt.xlabel(\"実際の値\", fontsize=12)\n",
        "plt.legend(fontsize=12)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "例２：LASSO回帰"
      ],
      "metadata": {
        "id": "VVQs7fK9pU_K"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlp301EuBXzX"
      },
      "source": [
        "# 機械学習の方法を選択\n",
        "# LASSO回帰のハイパーパラメタチューニングと回帰を両方実施（親切♪）\n",
        "from sklearn.linear_model import LassoCV\n",
        "model = LassoCV(n_alphas=50, cv=5, max_iter=100000)\n",
        "\n",
        "# 機械学習実行：ここから後ろは、RandomForestの時と変更なし\n",
        "model.fit(X_train, y_train)\n",
        "# 5-fold CVで決めたハイパーパラメタ(α)を表示\n",
        "print('alpha    = ', model.alpha_)\n",
        "# 検証\n",
        "print(\"Score for Training Data:\", model.score(X_train,y_train))\n",
        "print(\"Score for Test Data    :\", model.score(X_test ,y_test ))\n",
        "# 散布図描画\n",
        "plt.figure(figsize=(4,4))\n",
        "plt.scatter(y_train,model.predict(X_train),c='b',marker='o',alpha=0.7,label='Train')\n",
        "plt.scatter(y_test, model.predict(X_test ),c='r',marker='^',alpha=0.7,label='Test')\n",
        "x1 = np.linspace(-1, 50, 100)\n",
        "plt.plot(x1, x1, linestyle='-',c=\"silver\")\n",
        "plt.title(\"LASSO回帰\", fontsize=14)\n",
        "plt.ylabel(\"予測値\", fontsize=12)\n",
        "plt.xlabel(\"実際の値\", fontsize=12)\n",
        "plt.legend(fontsize=12)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}